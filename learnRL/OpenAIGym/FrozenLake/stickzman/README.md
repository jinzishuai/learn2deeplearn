# SRC

https://github.com/stickzman/honors_thesis/tree/master/Q-Value

# Results

## Q-Table (frozenlake-qmatrix.py)

The training results in a policy that is
```
qMatrix=[[ 0.22803855 -0.15200758 -0.16003714 -0.16845915]
 [-0.36       -0.38241627 -0.328       0.14745196]
 [-0.37834873 -0.4027119  -0.38013212 -0.00559167]
 [-0.41559839 -0.43670052 -0.47922178 -0.02421541]
 [ 0.2716074  -0.2        -0.2        -0.30032215]
 [ 0.          0.          0.          0.        ]
 [-0.7466272  -0.77618082 -0.0962548  -0.77370232]
 [ 0.          0.          0.          0.        ]
 [-0.2        -0.2        -0.2         0.35327095]
 [-0.2         0.45263036 -0.14332542 -0.2       ]
 [ 0.37973849 -0.47114296 -0.41504127 -0.38123081]
 [ 0.          0.          0.          0.        ]
 [ 0.          0.          0.          0.        ]
 [ 0.          0.          0.56038265  0.        ]
 [ 0.          0.          0.73051412  0.        ]
 [ 0.          0.          0.          0.        ]]

Policy is [[0 3 3 3]
 [0 0 2 0]
 [3 1 0 0]
 [0 2 2 0]]
```

Test results:
```python
E:\ShiJin\learn2deeplearn\learnRL\OpenAIGym\FrozenLake>python fl_human_policy.py
[2018-01-28 21:00:52,326] Making new env: FrozenLake-v0
policy=
[[ 0  3  3  3]
 [ 0 -1  2 -1]
 [ 3  1  0 -1]
 [-1  2  1 -1]]

7416 out of 10000 runs were successful

E:\ShiJin\learn2deeplearn\learnRL\OpenAIGym\FrozenLake>
```

## Neural Network
```
W=[array([[0.07707811, 0.07743613, 0.05690905, 0.06549056],
       [0.04810401, 0.06298799, 0.06106572, 0.0792643 ],
       [0.07799079, 0.08051004, 0.04388254, 0.04077262],
       [0.07850443, 0.00099332, 0.03039645, 0.00480242],
       [0.07775803, 0.07781999, 0.03354101, 0.07814128],
       [0.02926085, 0.07954594, 0.07645655, 0.05798868],
       [0.08035944, 0.05497998, 0.07974169, 0.06648182],
       [0.03088225, 0.06708653, 0.04476464, 0.04896046],
       [0.05158259, 0.01652159, 0.05311322, 0.07463389],
       [0.06044201, 0.00870198, 0.07485434, 0.06983808],
       [0.01332324, 0.05544639, 0.08134665, 0.04871619],
       [0.0774707 , 0.06142176, 0.01337106, 0.0687524 ],
       [0.08575246, 0.08634591, 0.05985294, 0.08462341],
       [0.06127442, 0.01305921, 0.0244824 , 0.00880224],
       [0.03757244, 0.05540637, 0.28961372, 0.08700482],
       [0.08897203, 0.03186285, 0.04602339, 0.04104283]], dtype=float32)]

policy=[array([[1, 3, 1, 0],
       [3, 1, 0, 1],
       [3, 2, 2, 0],
       [1, 0, 2, 0]], dtype=int64)]
```